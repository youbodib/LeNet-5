{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVL2rtJe9fAsnIXlhquzdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youbodib/LeNet-5/blob/main/LeNet_5_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0fQ_kIpc1AgL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chargement & Split du Dataset"
      ],
      "metadata": {
        "id": "28z5iYVZ4UFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(data_root):\n",
        "    X, y, class_names = [], [], sorted([d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))])\n",
        "    for label, class_dir in enumerate(class_names):\n",
        "        class_path = os.path.join(data_root, class_dir)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert('L').resize((32,32))\n",
        "                arr = np.asarray(img, dtype=np.float32) / 255.0\n",
        "                arr = arr[np.newaxis, ...]  # shape (1,32,32)\n",
        "                X.append(arr)\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    X = np.stack(X, axis=0)\n",
        "    y = np.array(y, dtype=np.int32)\n",
        "    return X, y, class_names\n",
        "\n",
        "DATA_ROOT = './tifinagh-data/amhcd-data-64/tifinagh-images'\n",
        "X, y, class_names = load_dataset(DATA_ROOT)\n",
        "perm = np.random.permutation(len(X))\n",
        "n_train = int(0.8 * len(X))\n",
        "X_train, y_train = X[perm[:n_train]], y[perm[:n_train]]\n",
        "X_test, y_test = X[perm[n_train:]], y[perm[n_train:]]"
      ],
      "metadata": {
        "id": "mOU6jIMP4Thz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "fLD1lHnA4h8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_batch(X):\n",
        "    X_aug = X.copy()\n",
        "    for i in range(X.shape[0]):\n",
        "        if random.random() < 0.5:\n",
        "            X_aug[i] = np.flip(X_aug[i], axis=2)  # horizontal flip\n",
        "        X_aug[i] += np.random.normal(0, 0.02, X_aug[i].shape)\n",
        "        X_aug[i] = np.clip(X_aug[i], 0, 1)\n",
        "    return X_aug"
      ],
      "metadata": {
        "id": "rXQvwLX64ajb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Couches From Scratch\n",
        "- Convolution *2D*"
      ],
      "metadata": {
        "id": "Oa8kaPgy4lFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D:\n",
        "    def __init__(self, in_ch, out_ch, kernel_size):\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.kernel_size = kernel_size\n",
        "        scale = np.sqrt(1. / (in_ch * kernel_size * kernel_size))\n",
        "        self.W = np.random.randn(out_ch, in_ch, kernel_size, kernel_size) * scale\n",
        "        self.b = np.zeros((out_ch, 1))\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        B, C, H, W = x.shape\n",
        "        out_h = H - self.kernel_size + 1\n",
        "        out_w = W - self.kernel_size + 1\n",
        "        y = np.zeros((B, self.out_ch, out_h, out_w))\n",
        "        for n in range(B):\n",
        "            for oc in range(self.out_ch):\n",
        "                for ic in range(self.in_ch):\n",
        "                    for i in range(out_h):\n",
        "                        for j in range(out_w):\n",
        "                            y[n, oc, i, j] += np.sum(\n",
        "                                x[n, ic, i:i+self.kernel_size, j:j+self.kernel_size] * self.W[oc, ic]\n",
        "                            )\n",
        "                y[n, oc] += self.b[oc]\n",
        "        return y\n",
        "\n",
        "    def backward(self, grad_y, lr):\n",
        "        x = self.x\n",
        "        B, C, H, W = x.shape\n",
        "        _, out_ch, out_h, out_w = grad_y.shape\n",
        "        self.dW.fill(0)\n",
        "        self.db.fill(0)\n",
        "        dx = np.zeros_like(x)\n",
        "        for n in range(B):\n",
        "            for oc in range(self.out_ch):\n",
        "                for ic in range(self.in_ch):\n",
        "                    for i in range(out_h):\n",
        "                        for j in range(out_w):\n",
        "                            patch = x[n, ic, i:i+self.kernel_size, j:j+self.kernel_size]\n",
        "                            self.dW[oc, ic] += grad_y[n, oc, i, j] * patch\n",
        "                            dx[n, ic, i:i+self.kernel_size, j:j+self.kernel_size] += grad_y[n, oc, i, j] * self.W[oc, ic]\n",
        "                self.db[oc] += np.sum(grad_y[n, oc])\n",
        "        self.W -= lr * self.dW / B\n",
        "        self.b -= lr * self.db / B\n",
        "        return dx"
      ],
      "metadata": {
        "id": "ZDnwet3Z4t-8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Average Pooling 2D"
      ],
      "metadata": {
        "id": "TbyJ4mkH41Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AvgPool2D:\n",
        "    def __init__(self, kernel, stride):\n",
        "        self.kernel = kernel\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        B, C, H, W = x.shape\n",
        "        out_h = (H - self.kernel) // self.stride + 1\n",
        "        out_w = (W - self.kernel) // self.stride + 1\n",
        "        y = np.zeros((B, C, out_h, out_w))\n",
        "        for n in range(B):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        y[n, c, i, j] = np.mean(x[n, c, h_start:h_start+self.kernel, w_start:w_start+self.kernel])\n",
        "        return y\n",
        "\n",
        "    def backward(self, grad_y, lr):\n",
        "        x = self.x\n",
        "        B, C, H, W = x.shape\n",
        "        dx = np.zeros_like(x)\n",
        "        out_h, out_w = grad_y.shape[2], grad_y.shape[3]\n",
        "        for n in range(B):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        dx[n, c, h_start:h_start+self.kernel, w_start:w_start+self.kernel] += grad_y[n, c, i, j] / (self.kernel*self.kernel)\n",
        "        return dx"
      ],
      "metadata": {
        "id": "Uen_AvsT44Tj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dense Layer"
      ],
      "metadata": {
        "id": "9ZWuqY0846lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        scale = np.sqrt(1. / in_dim)\n",
        "        self.W = np.random.randn(in_dim, out_dim) * scale\n",
        "        self.b = np.zeros(out_dim)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return x @ self.W + self.b\n",
        "\n",
        "    def backward(self, grad_y, lr):\n",
        "        self.dW = self.x.T @ grad_y\n",
        "        self.db = grad_y.sum(axis=0)\n",
        "        dx = grad_y @ self.W.T\n",
        "        self.W -= lr * self.dW / grad_y.shape[0]\n",
        "        self.b -= lr * self.db / grad_y.shape[0]\n",
        "        return dx"
      ],
      "metadata": {
        "id": "RGfwxVdG4-aL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Flatten"
      ],
      "metadata": {
        "id": "iBNdSy0W5Anb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def forward(self, x):\n",
        "        self.input_shape = x.shape\n",
        "        return x.reshape(x.shape[0], -1)\n",
        "    def backward(self, grad_y, lr):\n",
        "        return grad_y.reshape(self.input_shape)"
      ],
      "metadata": {
        "id": "LKIIbmeB5DVy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLU"
      ],
      "metadata": {
        "id": "vdYA3S1E5FJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.mask = (x > 0)\n",
        "        return x * self.mask\n",
        "    def backward(self, grad_y, lr):\n",
        "        return grad_y * self.mask"
      ],
      "metadata": {
        "id": "g5sJHHQy5H8D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax & Cross-Entropy"
      ],
      "metadata": {
        "id": "Ag0pFJYC5KOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy(probs, y_true):\n",
        "    N = y_true.shape[0]\n",
        "    return -np.log(probs[range(N), y_true] + 1e-9).mean()\n",
        "\n",
        "def grad_softmax_crossentropy(probs, y_true):\n",
        "    N = y_true.shape[0]\n",
        "    grad = probs.copy()\n",
        "    grad[range(N), y_true] -= 1\n",
        "    grad /= N\n",
        "    return grad"
      ],
      "metadata": {
        "id": "5Ip8t8we5Nbd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 Architecture (forward & backward)"
      ],
      "metadata": {
        "id": "WkhjUCFa5RAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5Scratch:\n",
        "    def __init__(self, num_classes):\n",
        "        self.conv1 = Conv2D(1, 6, 5)\n",
        "        self.relu1 = ReLU()\n",
        "        self.pool1 = AvgPool2D(2, 2)\n",
        "        self.conv2 = Conv2D(6, 16, 5)\n",
        "        self.relu2 = ReLU()\n",
        "        self.pool2 = AvgPool2D(2, 2)\n",
        "        self.conv3 = Conv2D(16, 120, 5)\n",
        "        self.relu3 = ReLU()\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(120, 84)\n",
        "        self.relu4 = ReLU()\n",
        "        self.fc2 = Dense(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1.forward(x)\n",
        "        x = self.relu1.forward(x)\n",
        "        x = self.pool1.forward(x)\n",
        "        x = self.conv2.forward(x)\n",
        "        x = self.relu2.forward(x)\n",
        "        x = self.pool2.forward(x)\n",
        "        x = self.conv3.forward(x)\n",
        "        x = self.relu3.forward(x)\n",
        "        x = self.flatten.forward(x)\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu4.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad, lr):\n",
        "        grad = self.fc2.backward(grad, lr)\n",
        "        grad = self.relu4.backward(grad, lr)\n",
        "        grad = self.fc1.backward(grad, lr)\n",
        "        grad = self.flatten.backward(grad, lr)\n",
        "        grad = self.relu3.backward(grad, lr)\n",
        "        grad = self.conv3.backward(grad, lr)\n",
        "        grad = self.pool2.backward(grad, lr)\n",
        "        grad = self.relu2.backward(grad, lr)\n",
        "        grad = self.conv2.backward(grad, lr)\n",
        "        grad = self.pool1.backward(grad, lr)\n",
        "        grad = self.relu1.backward(grad, lr)\n",
        "        grad = self.conv1.backward(grad, lr)\n",
        "        return grad"
      ],
      "metadata": {
        "id": "MGdqyTO45QOz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boucle d’entraînement"
      ],
      "metadata": {
        "id": "mPmSLogt5X9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32, lr=0.01):\n",
        "    N = X_train.shape[0]\n",
        "    for epoch in range(epochs):\n",
        "        perm = np.random.permutation(N)\n",
        "        X_train, y_train = X_train[perm], y_train[perm]\n",
        "        train_losses, train_accs = [], []\n",
        "        for i in range(0, N, batch_size):\n",
        "            Xb = X_train[i:i+batch_size]\n",
        "            yb = y_train[i:i+batch_size]\n",
        "            # Xb = augment_batch(Xb)  # décommente pour data augmentation\n",
        "            logits = model.forward(Xb)\n",
        "            probs = softmax(logits)\n",
        "            loss = cross_entropy(probs, yb)\n",
        "            preds = np.argmax(probs, axis=1)\n",
        "            acc = np.mean(preds == yb)\n",
        "            train_losses.append(loss)\n",
        "            train_accs.append(acc)\n",
        "            grad = grad_softmax_crossentropy(probs, yb)\n",
        "            model.backward(grad, lr)\n",
        "        val_acc = evaluate(model, X_val, y_val, batch_size)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {np.mean(train_losses):.4f} | Train acc: {np.mean(train_accs):.4f} | Val acc: {val_acc:.4f}\")\n",
        "\n",
        "def evaluate(model, X, y, batch_size=32):\n",
        "    N = X.shape[0]\n",
        "    accs = []\n",
        "    for i in range(0, N, batch_size):\n",
        "        Xb = X[i:i+batch_size]\n",
        "        yb = y[i:i+batch_size]\n",
        "        logits = model.forward(Xb)\n",
        "        probs = softmax(logits)\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "        acc = np.mean(preds == yb)\n",
        "        accs.append(acc)\n",
        "    return np.mean(accs)"
      ],
      "metadata": {
        "id": "A48TuZs95YyN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lancement de l’entraînement"
      ],
      "metadata": {
        "id": "Hfxjhz8n5evd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet5Scratch(num_classes=len(class_names))\n",
        "train(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32, lr=0.01)"
      ],
      "metadata": {
        "id": "0al9_0Km5dBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prédiction et Affichage"
      ],
      "metadata": {
        "id": "3-J2JduS5hHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher 10 images test et leur prédiction\n",
        "idxs = np.random.choice(len(X_test), 10, replace=False)\n",
        "plt.figure(figsize=(15,3))\n",
        "for i, idx in enumerate(idxs):\n",
        "    img = X_test[idx][0]\n",
        "    label = y_test[idx]\n",
        "    pred = np.argmax(softmax(model.forward(X_test[idx:idx+1])))\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"T:{class_names[label]}\\nP:{class_names[pred]}\", fontsize=8)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rwp8cXKH5hVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrice de confusion"
      ],
      "metadata": {
        "id": "UZPNw9wC5mqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "all_preds = np.argmax(softmax(model.forward(X_test)), axis=1)\n",
        "cm = confusion_matrix(y_test, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "plt.figure(figsize=(10,10))\n",
        "disp.plot(xticks_rotation=90, cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LMIAHOuJ5m8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}